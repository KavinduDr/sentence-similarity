{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCC9u8CoVPTN"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RLrRc5teVF7F"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import KeyedVectors\n",
        "import Levenshtein\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L52e3VfGUAc-"
      },
      "source": [
        "NLTK resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuCLOYEWT_XH",
        "outputId": "0a5a9ed4-ca58-4fc2-8580-a0b2bba5f960"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download NLTK resources\n",
        "# Install all required resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')  # The correct resource name\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjgbuk30UJDR"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZn_AsFFUL-U"
      },
      "outputs": [],
      "source": [
        "# Step 2: Text Preprocessing\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na28wfmiVFBB"
      },
      "source": [
        "Needed Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_9AqYeQUMyJ"
      },
      "outputs": [],
      "source": [
        "def get_wordnet_pos(treebank_tag):\n",
        "    \"\"\"Simplified POS mapping\"\"\"\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN  # Default to noun\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Updated preprocessing pipeline\"\"\"\n",
        "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
        "        return ''\n",
        "\n",
        "    # Case folding\n",
        "    text = text.lower()\n",
        "    # Remove Unicode characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    try:\n",
        "        pos_tags = nltk.pos_tag(tokens)\n",
        "    except LookupError:\n",
        "        nltk.download('averaged_perceptron_tagger')\n",
        "        pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    lemmatized = [\n",
        "        lemmatizer.lemmatize(token, get_wordnet_pos(tag))\n",
        "        for token, tag in pos_tags\n",
        "        if token not in stop_words and len(token) > 1\n",
        "    ]\n",
        "    return ' '.join(lemmatized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2bXBaLqVKhS"
      },
      "source": [
        "Load and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXMd3Ly9V5f8",
        "outputId": "9a36da2f-6aa0-40b8-b6f9-318236d59feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaqCsn2EVOvY"
      },
      "outputs": [],
      "source": [
        "# Step 3: Load and Preprocess Data\n",
        "df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/marking/data.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bckDT8iXVPlp",
        "outputId": "87aea14e-23ce-40a0-f61e-b3a7f78cc264"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvhs2ssUWmY8"
      },
      "source": [
        "Preprocess text fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7ihhiQjWl5N"
      },
      "outputs": [],
      "source": [
        "# Preprocess all text fields\n",
        "df['processed_correct'] = df['correct_answer'].apply(preprocess_text)\n",
        "df['processed_keywords'] = df['keywords'].apply(\n",
        "    lambda x: ' '.join([preprocess_text(k) for k in x.split(',')]))\n",
        "df['processed_student'] = df['student_answers'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ir4t3CzW95h"
      },
      "source": [
        "Combined reference creation (correct answer + keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaXVLYilWo7B"
      },
      "outputs": [],
      "source": [
        "# Create combined reference (correct answer + keywords)\n",
        "df['reference'] = df['processed_correct'] + ' ' + df['processed_keywords']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dv2AaBTXIUT"
      },
      "source": [
        "Similarity Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8yGN3YoXDd5"
      },
      "outputs": [],
      "source": [
        "# Step 4: Feature Engineering (Similarity Scores)\n",
        "# Load Word2Vec model for WMD (download and path setup required)\n",
        "# word2vec_model = KeyedVectors.load_word2vec_format('path/to/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "\n",
        "def calculate_features(row):\n",
        "    \"\"\"Calculate all similarity features for a row\"\"\"\n",
        "    ref = row['reference']\n",
        "    stu = row['processed_student']\n",
        "\n",
        "    # Cosine Similarity\n",
        "    tfidf = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf.fit_transform([ref, stu])\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "\n",
        "    # Jaccard Similarity\n",
        "    set_ref = set(ref.split())\n",
        "    set_stu = set(stu.split())\n",
        "    intersection = set_ref.intersection(set_stu)\n",
        "    union = set_ref.union(set_stu)\n",
        "    jaccard = len(intersection)/len(union) if union else 0\n",
        "\n",
        "    # Word Mover's Distance (Requires Word2Vec model)\n",
        "    wmd = 0  # Initialize with default value\n",
        "    # if word2vec_model:\n",
        "    #     wmd = word2vec_model.wmdistance(ref.split(), stu.split())\n",
        "\n",
        "    # Levenshtein Distance\n",
        "    lev = Levenshtein.distance(ref, stu)\n",
        "\n",
        "    # WordNet Similarity (Simplified version)\n",
        "    def wordnet_sim(text1, text2):\n",
        "        # ... (implementation from previous explanation)\n",
        "        return 0.5  # Placeholder\n",
        "\n",
        "    wordnet_s = wordnet_sim(ref, stu)\n",
        "\n",
        "    # BLEU Score\n",
        "    smooth = SmoothingFunction().method1\n",
        "    bleu = sentence_bleu([ref.split()], stu.split(), smoothing_function=smooth)\n",
        "\n",
        "    return [cosine_sim, jaccard, wmd, lev, wordnet_s, bleu]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl9jG8TcXM-2"
      },
      "source": [
        "Feature Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ6qlBuyXKPC"
      },
      "outputs": [],
      "source": [
        "# Apply feature calculation\n",
        "features = df.apply(calculate_features, axis=1, result_type='expand')\n",
        "features.columns = ['cosine', 'jaccard', 'wmd', 'levenshtein', 'wordnet', 'bleu']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4EmwAQhaTzs"
      },
      "source": [
        "Data normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFdRcBGdXPWD"
      },
      "outputs": [],
      "source": [
        "# Step 5: Data Normalization\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0yEEBW0ab7K"
      },
      "source": [
        "Splitting dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6ab_ybIaYej"
      },
      "outputs": [],
      "source": [
        "# Step 6: Train-Test Split\n",
        "X = scaled_features\n",
        "y = df['student_marks'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOWtadROagpl"
      },
      "source": [
        "Build and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE8iPcHpad2y",
        "outputId": "dc5ebe6e-6059-4611-9d11-0e2696c86f78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Build and Train Deep Learning Model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(6,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UlELs1QanBR"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07Gha99Oa7lz",
        "outputId": "db3ac495-390c-4eac-8340-e0389906dea5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 42.9784 - mae: 6.3022 - val_loss: 11.5521 - val_mae: 2.9468\n",
            "Epoch 2/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7102 - mae: 2.4516 - val_loss: 4.0447 - val_mae: 1.6301\n",
            "Epoch 3/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1193 - mae: 1.6337 - val_loss: 3.1476 - val_mae: 1.4165\n",
            "Epoch 4/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6810 - mae: 1.5434 - val_loss: 2.9796 - val_mae: 1.3681\n",
            "Epoch 5/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5675 - mae: 1.4919 - val_loss: 2.9738 - val_mae: 1.3796\n",
            "Epoch 6/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.6594 - mae: 1.5176 - val_loss: 2.9347 - val_mae: 1.3733\n",
            "Epoch 7/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5965 - mae: 1.5254 - val_loss: 2.7940 - val_mae: 1.3283\n",
            "Epoch 8/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.5565 - mae: 1.5152 - val_loss: 2.8182 - val_mae: 1.3448\n",
            "Epoch 9/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.3475 - mae: 1.4741 - val_loss: 2.7380 - val_mae: 1.3221\n",
            "Epoch 10/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.5121 - mae: 1.4957 - val_loss: 2.7288 - val_mae: 1.3223\n",
            "Epoch 11/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4737 - mae: 1.5003 - val_loss: 2.6548 - val_mae: 1.3032\n",
            "Epoch 12/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3.4124 - mae: 1.4934 - val_loss: 2.6450 - val_mae: 1.3040\n",
            "Epoch 13/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1233 - mae: 1.4132 - val_loss: 2.6078 - val_mae: 1.2950\n",
            "Epoch 14/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.1914 - mae: 1.4183 - val_loss: 2.5902 - val_mae: 1.2891\n",
            "Epoch 15/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.3285 - mae: 1.4697 - val_loss: 2.6068 - val_mae: 1.2962\n",
            "Epoch 16/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2944 - mae: 1.4410 - val_loss: 2.7412 - val_mae: 1.3309\n",
            "Epoch 17/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0914 - mae: 1.4367 - val_loss: 2.5897 - val_mae: 1.2912\n",
            "Epoch 18/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9953 - mae: 1.3824 - val_loss: 2.5413 - val_mae: 1.2792\n",
            "Epoch 19/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.4246 - mae: 1.4877 - val_loss: 2.6435 - val_mae: 1.3067\n",
            "Epoch 20/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0451 - mae: 1.4008 - val_loss: 2.5317 - val_mae: 1.2785\n",
            "Epoch 21/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9216 - mae: 1.3557 - val_loss: 2.5214 - val_mae: 1.2773\n",
            "Epoch 22/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1401 - mae: 1.4150 - val_loss: 2.5128 - val_mae: 1.2758\n",
            "Epoch 23/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3440 - mae: 1.4835 - val_loss: 2.5071 - val_mae: 1.2754\n",
            "Epoch 24/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2307 - mae: 1.4196 - val_loss: 2.6925 - val_mae: 1.3229\n",
            "Epoch 25/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3929 - mae: 1.4772 - val_loss: 2.5331 - val_mae: 1.2794\n",
            "Epoch 26/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0977 - mae: 1.3978 - val_loss: 2.5994 - val_mae: 1.2974\n",
            "Epoch 27/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2158 - mae: 1.4512 - val_loss: 2.4943 - val_mae: 1.2722\n",
            "Epoch 28/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2380 - mae: 1.4489 - val_loss: 2.5435 - val_mae: 1.2823\n",
            "Epoch 29/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0245 - mae: 1.3973 - val_loss: 2.6206 - val_mae: 1.3039\n",
            "Epoch 30/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0277 - mae: 1.4070 - val_loss: 2.4955 - val_mae: 1.2736\n",
            "Epoch 31/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2899 - mae: 1.4685 - val_loss: 2.6874 - val_mae: 1.3210\n",
            "Epoch 32/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3966 - mae: 1.4852 - val_loss: 2.6523 - val_mae: 1.3122\n",
            "Epoch 33/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2905 - mae: 1.4572 - val_loss: 2.4918 - val_mae: 1.2743\n",
            "Epoch 34/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7808 - mae: 1.3523 - val_loss: 2.5086 - val_mae: 1.2758\n",
            "Epoch 35/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3360 - mae: 1.4731 - val_loss: 2.5883 - val_mae: 1.2982\n",
            "Epoch 36/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0600 - mae: 1.3934 - val_loss: 2.4873 - val_mae: 1.2737\n",
            "Epoch 37/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0669 - mae: 1.4243 - val_loss: 2.5009 - val_mae: 1.2771\n",
            "Epoch 38/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1287 - mae: 1.4065 - val_loss: 2.5050 - val_mae: 1.2772\n",
            "Epoch 39/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0551 - mae: 1.3963 - val_loss: 2.5823 - val_mae: 1.2952\n",
            "Epoch 40/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8667 - mae: 1.3475 - val_loss: 2.4990 - val_mae: 1.2772\n",
            "Epoch 41/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0328 - mae: 1.4042 - val_loss: 2.4843 - val_mae: 1.2737\n",
            "Epoch 42/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1910 - mae: 1.4257 - val_loss: 2.4982 - val_mae: 1.2763\n",
            "Epoch 43/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2379 - mae: 1.4377 - val_loss: 2.4921 - val_mae: 1.2747\n",
            "Epoch 44/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9063 - mae: 1.3674 - val_loss: 2.4836 - val_mae: 1.2723\n",
            "Epoch 45/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1250 - mae: 1.4096 - val_loss: 2.5537 - val_mae: 1.2874\n",
            "Epoch 46/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1685 - mae: 1.4372 - val_loss: 2.5081 - val_mae: 1.2771\n",
            "Epoch 47/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1601 - mae: 1.4384 - val_loss: 2.4916 - val_mae: 1.2723\n",
            "Epoch 48/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1233 - mae: 1.4168 - val_loss: 2.4925 - val_mae: 1.2723\n",
            "Epoch 49/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2224 - mae: 1.4517 - val_loss: 2.5867 - val_mae: 1.2952\n",
            "Epoch 50/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9781 - mae: 1.3978 - val_loss: 2.4817 - val_mae: 1.2717\n",
            "Epoch 51/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.2963 - mae: 1.4495 - val_loss: 2.5820 - val_mae: 1.2950\n",
            "Epoch 52/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8968 - mae: 1.3698 - val_loss: 2.4935 - val_mae: 1.2740\n",
            "Epoch 53/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9506 - mae: 1.3962 - val_loss: 2.5276 - val_mae: 1.2814\n",
            "Epoch 54/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.8797 - mae: 1.3582 - val_loss: 2.5127 - val_mae: 1.2778\n",
            "Epoch 55/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1259 - mae: 1.4170 - val_loss: 2.4893 - val_mae: 1.2724\n",
            "Epoch 56/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9600 - mae: 1.3978 - val_loss: 2.5764 - val_mae: 1.2930\n",
            "Epoch 57/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1834 - mae: 1.4339 - val_loss: 2.5959 - val_mae: 1.2989\n",
            "Epoch 58/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.1512 - mae: 1.4322 - val_loss: 2.4859 - val_mae: 1.2727\n",
            "Epoch 59/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.1380 - mae: 1.4238 - val_loss: 2.5223 - val_mae: 1.2815\n",
            "Epoch 60/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9059 - mae: 1.3582 - val_loss: 2.5004 - val_mae: 1.2740\n",
            "Epoch 61/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1115 - mae: 1.4220 - val_loss: 2.5381 - val_mae: 1.2830\n",
            "Epoch 62/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1340 - mae: 1.4101 - val_loss: 2.5570 - val_mae: 1.2882\n",
            "Epoch 63/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1264 - mae: 1.4184 - val_loss: 2.4919 - val_mae: 1.2717\n",
            "Epoch 64/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1617 - mae: 1.4349 - val_loss: 2.4917 - val_mae: 1.2743\n",
            "Epoch 65/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9280 - mae: 1.3555 - val_loss: 2.5394 - val_mae: 1.2837\n",
            "Epoch 66/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0921 - mae: 1.4236 - val_loss: 2.4980 - val_mae: 1.2736\n",
            "Epoch 67/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9649 - mae: 1.3735 - val_loss: 2.5061 - val_mae: 1.2758\n",
            "Epoch 68/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9079 - mae: 1.3654 - val_loss: 2.4814 - val_mae: 1.2715\n",
            "Epoch 69/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9548 - mae: 1.3867 - val_loss: 2.5137 - val_mae: 1.2788\n",
            "Epoch 70/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8254 - mae: 1.3627 - val_loss: 2.5123 - val_mae: 1.2790\n",
            "Epoch 71/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8708 - mae: 1.3692 - val_loss: 2.4849 - val_mae: 1.2720\n",
            "Epoch 72/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1321 - mae: 1.4226 - val_loss: 2.4825 - val_mae: 1.2712\n",
            "Epoch 73/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8657 - mae: 1.3547 - val_loss: 2.4992 - val_mae: 1.2730\n",
            "Epoch 74/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1988 - mae: 1.4449 - val_loss: 2.5374 - val_mae: 1.2831\n",
            "Epoch 75/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0067 - mae: 1.3927 - val_loss: 2.4869 - val_mae: 1.2712\n",
            "Epoch 76/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1083 - mae: 1.4161 - val_loss: 2.5632 - val_mae: 1.2893\n",
            "Epoch 77/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8714 - mae: 1.3694 - val_loss: 2.5687 - val_mae: 1.2910\n",
            "Epoch 78/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9186 - mae: 1.3802 - val_loss: 2.5230 - val_mae: 1.2802\n",
            "Epoch 79/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0232 - mae: 1.3956 - val_loss: 2.4865 - val_mae: 1.2717\n",
            "Epoch 80/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0237 - mae: 1.4020 - val_loss: 2.5921 - val_mae: 1.2977\n",
            "Epoch 81/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0732 - mae: 1.4105 - val_loss: 2.5141 - val_mae: 1.2792\n",
            "Epoch 82/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0589 - mae: 1.3976 - val_loss: 2.5582 - val_mae: 1.2900\n",
            "Epoch 83/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0214 - mae: 1.4075 - val_loss: 2.5089 - val_mae: 1.2750\n",
            "Epoch 84/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0302 - mae: 1.3817 - val_loss: 2.4968 - val_mae: 1.2734\n",
            "Epoch 85/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9711 - mae: 1.3842 - val_loss: 2.6918 - val_mae: 1.3244\n",
            "Epoch 86/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8410 - mae: 1.3510 - val_loss: 2.5048 - val_mae: 1.2756\n",
            "Epoch 87/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.8969 - mae: 1.3628 - val_loss: 2.6211 - val_mae: 1.3058\n",
            "Epoch 88/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9469 - mae: 1.3796 - val_loss: 2.5286 - val_mae: 1.2824\n",
            "Epoch 89/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1342 - mae: 1.4157 - val_loss: 2.5157 - val_mae: 1.2804\n",
            "Epoch 90/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1520 - mae: 1.4230 - val_loss: 2.5357 - val_mae: 1.2844\n",
            "Epoch 91/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.1614 - mae: 1.4224 - val_loss: 2.6043 - val_mae: 1.3013\n",
            "Epoch 92/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0100 - mae: 1.3942 - val_loss: 2.4884 - val_mae: 1.2727\n",
            "Epoch 93/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.9686 - mae: 1.3845 - val_loss: 2.5889 - val_mae: 1.2971\n",
            "Epoch 94/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9229 - mae: 1.3701 - val_loss: 2.5218 - val_mae: 1.2808\n",
            "Epoch 95/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9692 - mae: 1.3816 - val_loss: 2.4975 - val_mae: 1.2760\n",
            "Epoch 96/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.0241 - mae: 1.4012 - val_loss: 2.5762 - val_mae: 1.2932\n",
            "Epoch 97/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.0264 - mae: 1.3930 - val_loss: 2.4814 - val_mae: 1.2704\n",
            "Epoch 98/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 3.0541 - mae: 1.3657 - val_loss: 2.5217 - val_mae: 1.2801\n",
            "Epoch 99/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 2.8441 - mae: 1.3669 - val_loss: 2.5078 - val_mae: 1.2770\n",
            "Epoch 100/100\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.9816 - mae: 1.3746 - val_loss: 2.5350 - val_mae: 1.2834\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlOCcNPCbuzb"
      },
      "source": [
        "Evaluation of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtD4-PPIa-Og",
        "outputId": "ea99ed47-ab37-4731-dc92-930cf003614f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6765 - mae: 1.2865 \n",
            "Test Loss: 2.7425\n",
            "Test MAE: 1.3068\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Evaluation\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test MAE: {mae:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTNK1D9mbwsS",
        "outputId": "907d5e21-4de4-4230-937c-84e2b2ca3d14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "sample_input = scaler.transform([[\n",
        "    0.8,  # cosine\n",
        "    0.75, # jaccard\n",
        "    0.2,  # wmd (normalized)\n",
        "    0.3,  # levenshtein (normalized)\n",
        "    0.6,  # wordnet\n",
        "    0.4   # bleu\n",
        "]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuvKKiipb0fq",
        "outputId": "584bba92-bd23-406c-b678-255b5060b779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Predicted Marks: 6.53\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict(sample_input)\n",
        "print(f'Predicted Marks: {prediction[0][0]:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fy-wWF-TcJDo"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def predict_marks(correct_answer, keywords, student_answer, model, scaler):\n",
        "    \"\"\"\n",
        "    Predicts marks based on the correct answer, keywords, and student answer.\n",
        "\n",
        "    Parameters:\n",
        "        correct_answer (str): The correct answer.\n",
        "        keywords (list): List of important keywords.\n",
        "        student_answer (str): The student's response.\n",
        "        model (tf.keras.Model): The trained deep learning model.\n",
        "        scaler (MinMaxScaler): The scaler used for feature normalization.\n",
        "\n",
        "    Returns:\n",
        "        float: Predicted marks for the student's answer.\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess inputs\n",
        "    processed_correct = preprocess_text(correct_answer)\n",
        "    processed_keywords = ' '.join([preprocess_text(k) for k in keywords])\n",
        "    processed_student = preprocess_text(student_answer)\n",
        "    reference = processed_correct + ' ' + processed_keywords\n",
        "\n",
        "    # Compute similarity features\n",
        "    tfidf = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf.fit_transform([reference, processed_student])\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "\n",
        "    set_ref = set(reference.split())\n",
        "    set_stu = set(processed_student.split())\n",
        "    jaccard = len(set_ref.intersection(set_stu)) / len(set_ref.union(set_stu)) if set_ref.union(set_stu) else 0\n",
        "\n",
        "    lev = Levenshtein.distance(reference, processed_student)\n",
        "\n",
        "    def wordnet_sim(text1, text2):\n",
        "        return 0.5  # Placeholder for actual implementation\n",
        "\n",
        "    wordnet_s = wordnet_sim(reference, processed_student)\n",
        "\n",
        "    smooth = SmoothingFunction().method1\n",
        "    bleu = sentence_bleu([reference.split()], processed_student.split(), smoothing_function=smooth)\n",
        "\n",
        "    # Prepare feature array as DataFrame with column names\n",
        "    feature_data = pd.DataFrame([[cosine_sim, jaccard, 0, lev, wordnet_s, bleu]],\n",
        "                                columns=['cosine', 'jaccard', 'wmd', 'levenshtein', 'wordnet', 'bleu'])\n",
        "\n",
        "    # Scale the features\n",
        "    scaled_features = scaler.transform(feature_data)\n",
        "\n",
        "    # Predict marks\n",
        "    prediction = model.predict(scaled_features)\n",
        "    return round(float(prediction[0][0]), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1V5FviVb4AR",
        "outputId": "2e14f4ee-16bd-45f5-8192-c428f2ee6dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Predicted Marks: 6.55\n"
          ]
        }
      ],
      "source": [
        "correct_answer = \"The mitochondria is the powerhouse of the cell.\"\n",
        "keywords = [\"mitochondria\", \"powerhouse\", \"cell\"]\n",
        "student_answer = \"Mitochondria is the energy producer in a cell.\"\n",
        "\n",
        "predicted_marks = predict_marks(correct_answer, keywords, student_answer, model, scaler)\n",
        "print(f\"Predicted Marks: {predicted_marks}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75quptcocAV6",
        "outputId": "9dc30020-33ab-44b4-9ae0-841119b729f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Collecting flask-cors\n",
            "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Downloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-5.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install flask flask-cors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htWiM9o0ed_I"
      },
      "source": [
        "saving the mdoel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSlff5ozdKZq",
        "outputId": "437e1fe9-516a-4159-e3b2-9ecb0838915a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "model.save(\"flask_app/model/model.h5\")\n",
        "pickle.dump(scaler, open(\"flask_app/model/scaler.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-ETqWmGegYG"
      },
      "source": [
        "or can use latest keras format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GvFE0Y6eio8"
      },
      "outputs": [],
      "source": [
        "# Save model in the newer .keras format\n",
        "model.save(\"flask_app/model/model.keras\")\n",
        "\n",
        "# Save scaler with pickle (this part remains the same)\n",
        "pickle.dump(scaler, open(\"flask_app/model/scaler.pkl\", \"wb\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URIvcjOqejFb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
