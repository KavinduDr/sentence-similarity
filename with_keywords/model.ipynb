{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCC9u8CoVPTN"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RLrRc5teVF7F"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import KeyedVectors\n",
        "import Levenshtein\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L52e3VfGUAc-"
      },
      "source": [
        "NLTK resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuCLOYEWT_XH",
        "outputId": "0a5a9ed4-ca58-4fc2-8580-a0b2bba5f960"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\rmkav\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\rmkav\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\rmkav\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\rmkav\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download NLTK resources\n",
        "# Install all required resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')  # The correct resource name\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjgbuk30UJDR"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xZn_AsFFUL-U"
      },
      "outputs": [],
      "source": [
        "# Step 2: Text Preprocessing\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na28wfmiVFBB"
      },
      "source": [
        "Needed Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "n_9AqYeQUMyJ"
      },
      "outputs": [],
      "source": [
        "def get_wordnet_pos(treebank_tag):\n",
        "    \"\"\"Simplified POS mapping\"\"\"\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN  # Default to noun\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Updated preprocessing pipeline\"\"\"\n",
        "    if not isinstance(text, str) or len(text.strip()) == 0:\n",
        "        return ''\n",
        "\n",
        "    # Case folding\n",
        "    text = text.lower()\n",
        "    # Remove Unicode characters\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', text)\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    try:\n",
        "        pos_tags = nltk.pos_tag(tokens)\n",
        "    except LookupError:\n",
        "        nltk.download('averaged_perceptron_tagger')\n",
        "        pos_tags = nltk.pos_tag(tokens)\n",
        "\n",
        "    lemmatized = [\n",
        "        lemmatizer.lemmatize(token, get_wordnet_pos(tag))\n",
        "        for token, tag in pos_tags\n",
        "        if token not in stop_words and len(token) > 1\n",
        "    ]\n",
        "    return ' '.join(lemmatized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2bXBaLqVKhS"
      },
      "source": [
        "Load and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXMd3Ly9V5f8",
        "outputId": "9a36da2f-6aa0-40b8-b6f9-318236d59feb"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qaqCsn2EVOvY"
      },
      "outputs": [],
      "source": [
        "# Step 3: Load and Preprocess Data\n",
        "df = pd.read_excel('dataset/data.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bckDT8iXVPlp",
        "outputId": "87aea14e-23ce-40a0-f61e-b3a7f78cc264"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     C:\\Users\\rmkav\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\rmkav\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvhs2ssUWmY8"
      },
      "source": [
        "Preprocess text fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Y7ihhiQjWl5N"
      },
      "outputs": [],
      "source": [
        "# Preprocess all text fields\n",
        "df['processed_correct'] = df['correct_answer'].apply(preprocess_text)\n",
        "df['processed_keywords'] = df['keywords'].apply(\n",
        "    lambda x: ' '.join([preprocess_text(k) for k in x.split(',')]))\n",
        "df['processed_student'] = df['student_answers'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ir4t3CzW95h"
      },
      "source": [
        "Combined reference creation (correct answer + keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YaXVLYilWo7B"
      },
      "outputs": [],
      "source": [
        "# Create combined reference (correct answer + keywords)\n",
        "df['reference'] = df['processed_correct'] + ' ' + df['processed_keywords']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dv2AaBTXIUT"
      },
      "source": [
        "Similarity Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d8yGN3YoXDd5"
      },
      "outputs": [],
      "source": [
        "# Step 4: Feature Engineering (Similarity Scores)\n",
        "# Load Word2Vec model for WMD (download and path setup required)\n",
        "# word2vec_model = KeyedVectors.load_word2vec_format('path/to/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "\n",
        "def calculate_features(row):\n",
        "    \"\"\"Calculate all similarity features for a row\"\"\"\n",
        "    ref = row['reference']\n",
        "    stu = row['processed_student']\n",
        "\n",
        "    # Cosine Similarity\n",
        "    tfidf = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf.fit_transform([ref, stu])\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "\n",
        "    # Jaccard Similarity\n",
        "    set_ref = set(ref.split())\n",
        "    set_stu = set(stu.split())\n",
        "    intersection = set_ref.intersection(set_stu)\n",
        "    union = set_ref.union(set_stu)\n",
        "    jaccard = len(intersection)/len(union) if union else 0\n",
        "\n",
        "    # Word Mover's Distance (Requires Word2Vec model)\n",
        "    wmd = 0  # Initialize with default value\n",
        "    # if word2vec_model:\n",
        "    #     wmd = word2vec_model.wmdistance(ref.split(), stu.split())\n",
        "\n",
        "    # Levenshtein Distance\n",
        "    lev = Levenshtein.distance(ref, stu)\n",
        "\n",
        "    # WordNet Similarity (Simplified version)\n",
        "    def wordnet_sim(text1, text2):\n",
        "        # ... (implementation from previous explanation)\n",
        "        return 0.5  # Placeholder\n",
        "\n",
        "    wordnet_s = wordnet_sim(ref, stu)\n",
        "\n",
        "    # BLEU Score\n",
        "    smooth = SmoothingFunction().method1\n",
        "    bleu = sentence_bleu([ref.split()], stu.split(), smoothing_function=smooth)\n",
        "\n",
        "    return [cosine_sim, jaccard, wmd, lev, wordnet_s, bleu]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl9jG8TcXM-2"
      },
      "source": [
        "Feature Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BJ6qlBuyXKPC"
      },
      "outputs": [],
      "source": [
        "# Apply feature calculation\n",
        "features = df.apply(calculate_features, axis=1, result_type='expand')\n",
        "features.columns = ['cosine', 'jaccard', 'wmd', 'levenshtein', 'wordnet', 'bleu']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4EmwAQhaTzs"
      },
      "source": [
        "Data normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KFdRcBGdXPWD"
      },
      "outputs": [],
      "source": [
        "# Step 5: Data Normalization\n",
        "scaler = MinMaxScaler()\n",
        "scaled_features = scaler.fit_transform(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0yEEBW0ab7K"
      },
      "source": [
        "Splitting dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "i6ab_ybIaYej"
      },
      "outputs": [],
      "source": [
        "# Step 6: Train-Test Split\n",
        "X = scaled_features\n",
        "y = df['student_marks'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOWtadROagpl"
      },
      "source": [
        "Build and train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE8iPcHpad2y",
        "outputId": "dc5ebe6e-6059-4611-9d11-0e2696c86f78"
      },
      "outputs": [],
      "source": [
        "# Step 7: Build and Train Deep Learning Model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(6,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5UlELs1QanBR"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07Gha99Oa7lz",
        "outputId": "db3ac495-390c-4eac-8340-e0389906dea5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "49/49 [==============================] - 3s 11ms/step - loss: 31.8235 - mae: 5.2475 - val_loss: 9.6672 - val_mae: 2.6704\n",
            "Epoch 2/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 6.4370 - mae: 2.0230 - val_loss: 3.8768 - val_mae: 1.5942\n",
            "Epoch 3/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 4.1318 - mae: 1.6437 - val_loss: 3.1733 - val_mae: 1.4174\n",
            "Epoch 4/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.6392 - mae: 1.5244 - val_loss: 3.0591 - val_mae: 1.3779\n",
            "Epoch 5/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.7177 - mae: 1.5482 - val_loss: 2.9808 - val_mae: 1.3744\n",
            "Epoch 6/100\n",
            "49/49 [==============================] - 0s 8ms/step - loss: 3.5848 - mae: 1.5206 - val_loss: 2.9254 - val_mae: 1.3639\n",
            "Epoch 7/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.6370 - mae: 1.5321 - val_loss: 2.8546 - val_mae: 1.3470\n",
            "Epoch 8/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.4411 - mae: 1.4820 - val_loss: 2.8005 - val_mae: 1.3329\n",
            "Epoch 9/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.4860 - mae: 1.4856 - val_loss: 2.7513 - val_mae: 1.3196\n",
            "Epoch 10/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.4795 - mae: 1.4941 - val_loss: 2.7136 - val_mae: 1.3112\n",
            "Epoch 11/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.3530 - mae: 1.4553 - val_loss: 2.7503 - val_mae: 1.3260\n",
            "Epoch 12/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.3751 - mae: 1.4861 - val_loss: 2.6578 - val_mae: 1.2998\n",
            "Epoch 13/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.4971 - mae: 1.5084 - val_loss: 2.6527 - val_mae: 1.3011\n",
            "Epoch 14/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.4952 - mae: 1.4993 - val_loss: 2.6289 - val_mae: 1.2957\n",
            "Epoch 15/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.4281 - mae: 1.4711 - val_loss: 2.6285 - val_mae: 1.2981\n",
            "Epoch 16/100\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 3.3623 - mae: 1.4756 - val_loss: 2.6076 - val_mae: 1.2920\n",
            "Epoch 17/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2994 - mae: 1.4563 - val_loss: 2.5832 - val_mae: 1.2874\n",
            "Epoch 18/100\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 3.3246 - mae: 1.4608 - val_loss: 2.6497 - val_mae: 1.3055\n",
            "Epoch 19/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2847 - mae: 1.4512 - val_loss: 2.5882 - val_mae: 1.2891\n",
            "Epoch 20/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.3982 - mae: 1.4620 - val_loss: 2.5783 - val_mae: 1.2882\n",
            "Epoch 21/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.3327 - mae: 1.4707 - val_loss: 2.6577 - val_mae: 1.3091\n",
            "Epoch 22/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.1878 - mae: 1.4436 - val_loss: 2.5391 - val_mae: 1.2806\n",
            "Epoch 23/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.3028 - mae: 1.4411 - val_loss: 2.5993 - val_mae: 1.2974\n",
            "Epoch 24/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.0928 - mae: 1.4089 - val_loss: 2.5500 - val_mae: 1.2836\n",
            "Epoch 25/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.2444 - mae: 1.4458 - val_loss: 2.5416 - val_mae: 1.2840\n",
            "Epoch 26/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.2037 - mae: 1.4350 - val_loss: 2.6368 - val_mae: 1.3057\n",
            "Epoch 27/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.3108 - mae: 1.4583 - val_loss: 2.5251 - val_mae: 1.2794\n",
            "Epoch 28/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2182 - mae: 1.4424 - val_loss: 2.5259 - val_mae: 1.2806\n",
            "Epoch 29/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.2965 - mae: 1.4561 - val_loss: 2.5735 - val_mae: 1.2900\n",
            "Epoch 30/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2701 - mae: 1.4369 - val_loss: 2.6127 - val_mae: 1.3010\n",
            "Epoch 31/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1765 - mae: 1.4410 - val_loss: 2.5549 - val_mae: 1.2847\n",
            "Epoch 32/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.2413 - mae: 1.4397 - val_loss: 2.5252 - val_mae: 1.2807\n",
            "Epoch 33/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1669 - mae: 1.4276 - val_loss: 2.5304 - val_mae: 1.2817\n",
            "Epoch 34/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.2167 - mae: 1.4393 - val_loss: 2.4985 - val_mae: 1.2750\n",
            "Epoch 35/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.2143 - mae: 1.4303 - val_loss: 2.6211 - val_mae: 1.3044\n",
            "Epoch 36/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.1578 - mae: 1.4107 - val_loss: 2.4956 - val_mae: 1.2732\n",
            "Epoch 37/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2396 - mae: 1.4374 - val_loss: 2.5518 - val_mae: 1.2848\n",
            "Epoch 38/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1776 - mae: 1.4233 - val_loss: 2.4968 - val_mae: 1.2737\n",
            "Epoch 39/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2025 - mae: 1.4178 - val_loss: 2.5741 - val_mae: 1.2924\n",
            "Epoch 40/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.3351 - mae: 1.4682 - val_loss: 2.5937 - val_mae: 1.2946\n",
            "Epoch 41/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1944 - mae: 1.4262 - val_loss: 2.5026 - val_mae: 1.2753\n",
            "Epoch 42/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.2143 - mae: 1.4368 - val_loss: 2.6332 - val_mae: 1.3078\n",
            "Epoch 43/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.2047 - mae: 1.4454 - val_loss: 2.5775 - val_mae: 1.2922\n",
            "Epoch 44/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.3554 - mae: 1.4789 - val_loss: 2.5071 - val_mae: 1.2759\n",
            "Epoch 45/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1030 - mae: 1.4163 - val_loss: 2.5601 - val_mae: 1.2889\n",
            "Epoch 46/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.1321 - mae: 1.4234 - val_loss: 2.5242 - val_mae: 1.2815\n",
            "Epoch 47/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2788 - mae: 1.4680 - val_loss: 2.5067 - val_mae: 1.2763\n",
            "Epoch 48/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.2294 - mae: 1.4381 - val_loss: 2.6483 - val_mae: 1.3120\n",
            "Epoch 49/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.1287 - mae: 1.4367 - val_loss: 2.5132 - val_mae: 1.2793\n",
            "Epoch 50/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.0737 - mae: 1.4104 - val_loss: 2.5078 - val_mae: 1.2768\n",
            "Epoch 51/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1787 - mae: 1.4311 - val_loss: 2.5253 - val_mae: 1.2803\n",
            "Epoch 52/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1373 - mae: 1.4077 - val_loss: 2.6638 - val_mae: 1.3156\n",
            "Epoch 53/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1929 - mae: 1.4434 - val_loss: 2.5048 - val_mae: 1.2768\n",
            "Epoch 54/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.2062 - mae: 1.4405 - val_loss: 2.4984 - val_mae: 1.2757\n",
            "Epoch 55/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1238 - mae: 1.4358 - val_loss: 2.4944 - val_mae: 1.2741\n",
            "Epoch 56/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.0358 - mae: 1.3954 - val_loss: 2.5234 - val_mae: 1.2788\n",
            "Epoch 57/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.0806 - mae: 1.3996 - val_loss: 2.5263 - val_mae: 1.2805\n",
            "Epoch 58/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1179 - mae: 1.4181 - val_loss: 2.5448 - val_mae: 1.2853\n",
            "Epoch 59/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1929 - mae: 1.4304 - val_loss: 2.5175 - val_mae: 1.2789\n",
            "Epoch 60/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1508 - mae: 1.4239 - val_loss: 2.5005 - val_mae: 1.2745\n",
            "Epoch 61/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1810 - mae: 1.4353 - val_loss: 2.6562 - val_mae: 1.3141\n",
            "Epoch 62/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1876 - mae: 1.4363 - val_loss: 2.6217 - val_mae: 1.3056\n",
            "Epoch 63/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1229 - mae: 1.4121 - val_loss: 2.5615 - val_mae: 1.2903\n",
            "Epoch 64/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.0196 - mae: 1.3775 - val_loss: 2.5089 - val_mae: 1.2787\n",
            "Epoch 65/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.2282 - mae: 1.4449 - val_loss: 2.5381 - val_mae: 1.2849\n",
            "Epoch 66/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.1275 - mae: 1.4167 - val_loss: 2.5885 - val_mae: 1.2971\n",
            "Epoch 67/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 2.9921 - mae: 1.3899 - val_loss: 2.4922 - val_mae: 1.2736\n",
            "Epoch 68/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.0999 - mae: 1.3996 - val_loss: 2.4920 - val_mae: 1.2750\n",
            "Epoch 69/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.0839 - mae: 1.4083 - val_loss: 2.5604 - val_mae: 1.2907\n",
            "Epoch 70/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 2.9760 - mae: 1.3941 - val_loss: 2.4898 - val_mae: 1.2730\n",
            "Epoch 71/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.0241 - mae: 1.3844 - val_loss: 2.5446 - val_mae: 1.2853\n",
            "Epoch 72/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.0089 - mae: 1.3925 - val_loss: 2.5072 - val_mae: 1.2775\n",
            "Epoch 73/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.1369 - mae: 1.4253 - val_loss: 2.4925 - val_mae: 1.2737\n",
            "Epoch 74/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.1413 - mae: 1.4134 - val_loss: 2.4968 - val_mae: 1.2742\n",
            "Epoch 75/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.0729 - mae: 1.3964 - val_loss: 2.5359 - val_mae: 1.2827\n",
            "Epoch 76/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.0974 - mae: 1.4123 - val_loss: 2.5055 - val_mae: 1.2750\n",
            "Epoch 77/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.0839 - mae: 1.4067 - val_loss: 2.6056 - val_mae: 1.2993\n",
            "Epoch 78/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.9536 - mae: 1.3913 - val_loss: 2.4945 - val_mae: 1.2724\n",
            "Epoch 79/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.9740 - mae: 1.3820 - val_loss: 2.4936 - val_mae: 1.2741\n",
            "Epoch 80/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 2.9905 - mae: 1.3862 - val_loss: 2.5045 - val_mae: 1.2768\n",
            "Epoch 81/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.0407 - mae: 1.4046 - val_loss: 2.5296 - val_mae: 1.2804\n",
            "Epoch 82/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.0289 - mae: 1.3983 - val_loss: 2.5049 - val_mae: 1.2757\n",
            "Epoch 83/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 3.0816 - mae: 1.4152 - val_loss: 2.4975 - val_mae: 1.2746\n",
            "Epoch 84/100\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 2.9803 - mae: 1.3813 - val_loss: 2.4931 - val_mae: 1.2732\n",
            "Epoch 85/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.9515 - mae: 1.3879 - val_loss: 2.5173 - val_mae: 1.2785\n",
            "Epoch 86/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.0617 - mae: 1.4074 - val_loss: 2.4904 - val_mae: 1.2724\n",
            "Epoch 87/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.9869 - mae: 1.3920 - val_loss: 2.5203 - val_mae: 1.2806\n",
            "Epoch 88/100\n",
            "49/49 [==============================] - 0s 8ms/step - loss: 3.0040 - mae: 1.3825 - val_loss: 2.5031 - val_mae: 1.2780\n",
            "Epoch 89/100\n",
            "49/49 [==============================] - 0s 8ms/step - loss: 2.8734 - mae: 1.3684 - val_loss: 2.5040 - val_mae: 1.2769\n",
            "Epoch 90/100\n",
            "49/49 [==============================] - 0s 8ms/step - loss: 3.0651 - mae: 1.4029 - val_loss: 2.5065 - val_mae: 1.2779\n",
            "Epoch 91/100\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 3.0477 - mae: 1.3854 - val_loss: 2.5362 - val_mae: 1.2843\n",
            "Epoch 92/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.9830 - mae: 1.3834 - val_loss: 2.4972 - val_mae: 1.2743\n",
            "Epoch 93/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 2.9296 - mae: 1.3671 - val_loss: 2.5103 - val_mae: 1.2788\n",
            "Epoch 94/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.0211 - mae: 1.3926 - val_loss: 2.5293 - val_mae: 1.2828\n",
            "Epoch 95/100\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 3.0162 - mae: 1.3819 - val_loss: 2.4976 - val_mae: 1.2756\n",
            "Epoch 96/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.0861 - mae: 1.3980 - val_loss: 2.4934 - val_mae: 1.2726\n",
            "Epoch 97/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 3.0852 - mae: 1.4120 - val_loss: 2.5491 - val_mae: 1.2867\n",
            "Epoch 98/100\n",
            "49/49 [==============================] - 0s 7ms/step - loss: 3.0233 - mae: 1.3953 - val_loss: 2.4865 - val_mae: 1.2736\n",
            "Epoch 99/100\n",
            "49/49 [==============================] - 0s 8ms/step - loss: 3.0401 - mae: 1.3950 - val_loss: 2.5296 - val_mae: 1.2824\n",
            "Epoch 100/100\n",
            "49/49 [==============================] - 0s 6ms/step - loss: 2.9496 - mae: 1.3744 - val_loss: 2.4898 - val_mae: 1.2734\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlOCcNPCbuzb"
      },
      "source": [
        "Evaluation of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtD4-PPIa-Og",
        "outputId": "ea99ed47-ab37-4731-dc92-930cf003614f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 3ms/step - loss: 2.7210 - mae: 1.3003\n",
            "Test Loss: 2.7210\n",
            "Test MAE: 1.3003\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Evaluation\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test MAE: {mae:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTNK1D9mbwsS",
        "outputId": "907d5e21-4de4-4230-937c-84e2b2ca3d14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\Anaconda\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "sample_input = scaler.transform([[\n",
        "    0.8,  # cosine\n",
        "    0.75, # jaccard\n",
        "    0.2,  # wmd (normalized)\n",
        "    0.3,  # levenshtein (normalized)\n",
        "    0.6,  # wordnet\n",
        "    0.4   # bleu\n",
        "]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuvKKiipb0fq",
        "outputId": "584bba92-bd23-406c-b678-255b5060b779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 115ms/step\n",
            "Predicted Marks: 6.61\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict(sample_input)\n",
        "print(f'Predicted Marks: {prediction[0][0]:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Fy-wWF-TcJDo"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def predict_marks(correct_answer, keywords, student_answer, model, scaler):\n",
        "    \"\"\"\n",
        "    Predicts marks based on the correct answer, keywords, and student answer.\n",
        "\n",
        "    Parameters:\n",
        "        correct_answer (str): The correct answer.\n",
        "        keywords (list): List of important keywords.\n",
        "        student_answer (str): The student's response.\n",
        "        model (tf.keras.Model): The trained deep learning model.\n",
        "        scaler (MinMaxScaler): The scaler used for feature normalization.\n",
        "\n",
        "    Returns:\n",
        "        float: Predicted marks for the student's answer.\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess inputs\n",
        "    processed_correct = preprocess_text(correct_answer)\n",
        "    processed_keywords = ' '.join([preprocess_text(k) for k in keywords])\n",
        "    processed_student = preprocess_text(student_answer)\n",
        "    reference = processed_correct + ' ' + processed_keywords\n",
        "\n",
        "    # Compute similarity features\n",
        "    tfidf = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf.fit_transform([reference, processed_student])\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "\n",
        "    set_ref = set(reference.split())\n",
        "    set_stu = set(processed_student.split())\n",
        "    jaccard = len(set_ref.intersection(set_stu)) / len(set_ref.union(set_stu)) if set_ref.union(set_stu) else 0\n",
        "\n",
        "    lev = Levenshtein.distance(reference, processed_student)\n",
        "\n",
        "    def wordnet_sim(text1, text2):\n",
        "        return 0.5  # Placeholder for actual implementation\n",
        "\n",
        "    wordnet_s = wordnet_sim(reference, processed_student)\n",
        "\n",
        "    smooth = SmoothingFunction().method1\n",
        "    bleu = sentence_bleu([reference.split()], processed_student.split(), smoothing_function=smooth)\n",
        "\n",
        "    # Prepare feature array as DataFrame with column names\n",
        "    feature_data = pd.DataFrame([[cosine_sim, jaccard, 0, lev, wordnet_s, bleu]],\n",
        "                                columns=['cosine', 'jaccard', 'wmd', 'levenshtein', 'wordnet', 'bleu'])\n",
        "\n",
        "    # Scale the features\n",
        "    scaled_features = scaler.transform(feature_data)\n",
        "\n",
        "    # Predict marks\n",
        "    prediction = model.predict(scaled_features)\n",
        "    return round(float(prediction[0][0]), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1V5FviVb4AR",
        "outputId": "2e14f4ee-16bd-45f5-8192-c428f2ee6dc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "Predicted Marks: 6.76\n"
          ]
        }
      ],
      "source": [
        "correct_answer = \"The mitochondria is the powerhouse of the cell.\"\n",
        "keywords = [\"mitochondria\", \"powerhouse\", \"cell\"]\n",
        "student_answer = \"Mitochondria is the energy producer in a cell.\"\n",
        "\n",
        "predicted_marks = predict_marks(correct_answer, keywords, student_answer, model, scaler)\n",
        "print(f\"Predicted Marks: {predicted_marks}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75quptcocAV6",
        "outputId": "9dc30020-33ab-44b4-9ae0-841119b729f1"
      },
      "outputs": [],
      "source": [
        "# !pip install flask flask-cors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htWiM9o0ed_I"
      },
      "source": [
        "saving the mdoel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSlff5ozdKZq",
        "outputId": "437e1fe9-516a-4159-e3b2-9ecb0838915a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: flask_app/model/saved_model\\assets\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save in SavedModel format\n",
        "model.save(\"flask_app/model/saved_model\")\n",
        "\n",
        "pickle.dump(scaler, open(\"flask_app/model/scaler.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-ETqWmGegYG"
      },
      "source": [
        "or can use latest keras format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_GvFE0Y6eio8"
      },
      "outputs": [],
      "source": [
        "# # Save model in the newer .keras format\n",
        "# model.save(\"flask_app/model/model.keras\")\n",
        "\n",
        "# # Save scaler with pickle (this part remains the same)\n",
        "# pickle.dump(scaler, open(\"flask_app/model/scaler.pkl\", \"wb\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URIvcjOqejFb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
